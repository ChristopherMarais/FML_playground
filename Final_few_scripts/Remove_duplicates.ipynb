{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f30e95c-3f32-42cf-bcc6-cc18c011f675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T03:09:01.350308Z",
     "iopub.status.busy": "2022-07-27T03:09:01.350100Z",
     "iopub.status.idle": "2022-07-27T03:09:01.876367Z",
     "shell.execute_reply": "2022-07-27T03:09:01.875750Z",
     "shell.execute_reply.started": "2022-07-27T03:09:01.350273Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799acc4c-cd4a-4d5d-9628-d9463a212ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T03:09:01.877311Z",
     "iopub.status.busy": "2022-07-27T03:09:01.877038Z",
     "iopub.status.idle": "2022-07-27T03:09:02.406163Z",
     "shell.execute_reply": "2022-07-27T03:09:02.405444Z",
     "shell.execute_reply.started": "2022-07-27T03:09:01.877290Z"
    }
   },
   "outputs": [],
   "source": [
    "# working directory\n",
    "wd = os.getcwd()\n",
    "\n",
    "# Loading Data\n",
    "labels_train = np.load(wd+'/labels.npy')\n",
    "data_train = np.load(wd+'/data.npy')\n",
    "\n",
    "# change labels data type to int\n",
    "labels_train = np.array(labels_train,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626f768f-3c5c-4a19-be86-4e8241989089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T03:09:02.407076Z",
     "iopub.status.busy": "2022-07-27T03:09:02.406859Z",
     "iopub.status.idle": "2022-07-27T03:14:10.736126Z",
     "shell.execute_reply": "2022-07-27T03:14:10.734797Z",
     "shell.execute_reply.started": "2022-07-27T03:09:02.407054Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add all data to a dataframe to remove duplicate data points\n",
    "df = pd.DataFrame(data_train).T\n",
    "df['label'] = labels_train\n",
    "s = df.apply(lambda x: hash(tuple(x)), axis = 1)\n",
    "non_dup_idx_lst = list(s.drop_duplicates().index)\n",
    "labels_train = labels_train[non_dup_idx_lst]\n",
    "data_train = data_train[:,non_dup_idx_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde501a8-e718-4347-a8ba-a47614c2682c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T03:14:10.737952Z",
     "iopub.status.busy": "2022-07-27T03:14:10.737716Z",
     "iopub.status.idle": "2022-07-27T03:14:11.765288Z",
     "shell.execute_reply": "2022-07-27T03:14:11.764595Z",
     "shell.execute_reply.started": "2022-07-27T03:14:10.737929Z"
    }
   },
   "outputs": [],
   "source": [
    "# save data to disk\n",
    "np.save('nodup_data', data_train)\n",
    "np.save('nodup_labels', labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ac430-a482-4e30-a98f-7cff69ece841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make multi class array\n",
    "df = pd.DataFrame(data_train) # turn images into dataframe\n",
    "s = df.apply(lambda x: hash(tuple(x)), axis = 0) # hash all the images\n",
    "duplicate_index_dict = s.groupby(s).groups # find duplicate iamges and their indexes\n",
    "labels_train_2d = list(np.expand_dims(labels_train, axis=1)) #make each element in array an array and turn into a list\n",
    "\n",
    "# make single image have multiple classes\n",
    "for i in duplicate_index_dict.values():\n",
    "    if len(i) > 1:\n",
    "        idx_lst = list(i)\n",
    "        for j in idx_lst:\n",
    "            labels_train_2d[j] = np.array(labels_train[idx_lst])\n",
    "labels_train_2d = np.array(labels_train_2d, dtype=object)\n",
    "\n",
    "# # remove duplicates again\n",
    "df = pd.DataFrame(s)\n",
    "df['label'] = list(map(str,labels_train_2d))\n",
    "s = df.apply(lambda x: hash(tuple(x)), axis = 1)\n",
    "non_dup_idx_lst = list(s.drop_duplicates().index)\n",
    "labels_train_multi_nodup = labels_train_2d[non_dup_idx_lst]\n",
    "data_train_multi_nodup = data_train[:,non_dup_idx_lst]\n",
    "\n",
    "np.save('multi_data', data_train_multi_nodup)\n",
    "np.save('multi_labels', labels_train_multi_nodup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FML_a100",
   "language": "python",
   "name": "fml_a100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
