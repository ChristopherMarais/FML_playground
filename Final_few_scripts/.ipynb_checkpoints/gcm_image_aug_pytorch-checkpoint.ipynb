{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "674ace41-aec8-4ace-8231-09ae65619060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T18:36:08.803170Z",
     "iopub.status.busy": "2022-07-31T18:36:08.802668Z",
     "iopub.status.idle": "2022-07-31T18:36:08.817670Z",
     "shell.execute_reply": "2022-07-31T18:36:08.817169Z",
     "shell.execute_reply.started": "2022-07-31T18:36:08.803170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x24ce7152290>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, accuracy_score, f1_score\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "364c10c9-bee2-4b7d-8985-7ba9b77344a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T18:36:08.985527Z",
     "iopub.status.busy": "2022-07-31T18:36:08.985026Z",
     "iopub.status.idle": "2022-07-31T18:36:09.096402Z",
     "shell.execute_reply": "2022-07-31T18:36:09.095402Z",
     "shell.execute_reply.started": "2022-07-31T18:36:08.985527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:  NVIDIA GeForce RTX 3060\n",
      "CPU cores:  16\n",
      "Working directory:  C:\\Users\\GCM\\Desktop\\GIT_REPOS\\FML_playground\\Final_few_scripts\n",
      "14:36:09\n"
     ]
    }
   ],
   "source": [
    "# use GPU when available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# Print GPU name\n",
    "print('GPU: ', torch.cuda.get_device_name(device=device))\n",
    "#number of usable CPU cores\n",
    "core_count = os.cpu_count() #len(os.sched_getaffinity(0)) for server/linux system\n",
    "print('CPU cores: ', core_count)\n",
    "# current working directory\n",
    "wd = os.getcwd()\n",
    "print('Working directory: ', wd)\n",
    "\n",
    "# start time\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94716e8-a580-4656-97ac-f087a3c3d4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T18:01:08.174112Z",
     "iopub.status.busy": "2022-07-31T18:01:08.174112Z",
     "iopub.status.idle": "2022-07-31T18:02:08.054614Z",
     "shell.execute_reply": "2022-07-31T18:02:08.054113Z",
     "shell.execute_reply.started": "2022-07-31T18:01:08.174112Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "data = np.load(wd+'/nodup_data.npy')\n",
    "labels = np.load(wd+'/nodup_labels.npy')\n",
    "\n",
    "# reshape data\n",
    "reshaped_data = data.reshape((300,300,3,data.shape[1]))\n",
    "moveaxis_data = np.moveaxis(reshaped_data, source=[0, 1, 2, 3], destination=[2, 3, 1, 0])\n",
    "labels = np.array(labels,dtype=int)\n",
    "\n",
    "# label names\n",
    "class_names = ['Stop','Yield','Red Light','Green Light','Roundabout','Right Turn Only',\n",
    "                'Do Not Enter','Crosswalk','Handicap Parking','No Parking']\n",
    "\n",
    "# turn into tensors\n",
    "# # and scale data\n",
    "# to_tensor = transforms.ToTensor()\n",
    "# to_tensor(reshaped_data[:,:,:,0])\n",
    "data_te = torch.Tensor(moveaxis_data)\n",
    "labels_te = torch.Tensor(labels)\n",
    "\n",
    "# create additional images\n",
    "\n",
    "# normalize parameters\n",
    "stds = reshaped_data.std(axis=(0,1,3))\n",
    "means = reshaped_data.mean(axis=(0,1,3))\n",
    "normalize = torch.nn.Sequential(transforms.Normalize(means, stds)) # in shape of data_te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3a2c7c1-763c-44bb-a0e8-b025adadc1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T18:44:40.197872Z",
     "iopub.status.busy": "2022-07-31T18:44:40.197872Z",
     "iopub.status.idle": "2022-07-31T18:44:41.964371Z",
     "shell.execute_reply": "2022-07-31T18:44:41.963369Z",
     "shell.execute_reply.started": "2022-07-31T18:44:40.197872Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, dataset, transform_list=None):\n",
    "        [data_X, data_y] = dataset\n",
    "        X_tensor, y_tensor = torch.Tensor(data_X), torch.Tensor(data_y)\n",
    "        tensors = (X_tensor, y_tensor)\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transforms = transform_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transforms:\n",
    "          #for transform in self.transforms: \n",
    "          #  x = transform(x)\n",
    "            x = self.transforms(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)\n",
    "\n",
    "\n",
    "trainset = [moveaxis_data,labels]\n",
    "\n",
    "transorm_comp = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=(0.75,1.25), \n",
    "                           contrast=(0,2), \n",
    "                           saturation=(0,2), \n",
    "                           hue=(-0.5,0.5)),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), \n",
    "                            sigma=(0.1, 5)),\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.RandomAffine(degrees=(0, 360), \n",
    "                            translate=(0.1, 0.3), \n",
    "                            scale=(0.5, 0.75), \n",
    "                            shear=(0, 0.2, 0, 0.2)),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "    transforms.Normalize(means, stds)\n",
    "    ])\n",
    "\n",
    "dataset_train = CustomTensorDataset(dataset=trainset, transform_list=transorm_comp)\n",
    "\n",
    "dataset_dataloader = torch.utils.data.DataLoader(dataset_train, \n",
    "                                                 batch_size=4,\n",
    "                                                 shuffle=True, \n",
    "                                                 num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d99a0d7-4071-4b46-8896-689eed7388d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T18:02:08.056113Z",
     "iopub.status.busy": "2022-07-31T18:02:08.056113Z",
     "iopub.status.idle": "2022-07-31T18:02:08.070614Z",
     "shell.execute_reply": "2022-07-31T18:02:08.069614Z",
     "shell.execute_reply.started": "2022-07-31T18:02:08.056113Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x24b5c30c280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorDataset(data_te,labels_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28429c33-cdbc-4bfb-9a48-aedf4a2c28ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T15:13:18.972265Z",
     "iopub.status.busy": "2022-07-31T15:13:18.972265Z",
     "iopub.status.idle": "2022-07-31T15:13:18.986767Z",
     "shell.execute_reply": "2022-07-31T15:13:18.986264Z",
     "shell.execute_reply.started": "2022-07-31T15:13:18.972265Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transforms.ToTensor()\n",
    "\n",
    "# transforms.functional.adjust_hue()\n",
    "# transforms.functional.adjust_brightness()\n",
    "# transforms.functional.adjust_contrast()\n",
    "# transforms.functional.adjust_gamma()\n",
    "# transforms.functional.adjust_saturation()\n",
    "# transforms.functional.adjust_sharpness()\n",
    "# transforms.functional.gaussian_blur()\n",
    "# transforms.functional.hflip()\n",
    "# transforms.functional.vflip()\n",
    "# transforms.functional.rotate()\n",
    "\n",
    "# transforms.functional.perspective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9103ffe2-2fd3-4850-9541-9d36aefaa205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T15:13:18.988265Z",
     "iopub.status.busy": "2022-07-31T15:13:18.987765Z",
     "iopub.status.idle": "2022-07-31T15:13:19.449731Z",
     "shell.execute_reply": "2022-07-31T15:13:19.449231Z",
     "shell.execute_reply.started": "2022-07-31T15:13:18.988265Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(torch.moveaxis(test_0, (0,1,2), (2,0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4bfa11f-1f3b-4ed2-9460-a0732928132d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T18:36:37.064325Z",
     "iopub.status.busy": "2022-07-31T18:36:37.064325Z",
     "iopub.status.idle": "2022-07-31T18:36:37.157324Z",
     "shell.execute_reply": "2022-07-31T18:36:37.155324Z",
     "shell.execute_reply.started": "2022-07-31T18:36:37.064325Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m data_transforms \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      3\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     ]),\n\u001b[0;32m     26\u001b[0m }\n\u001b[1;32m---> 28\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x: datasets\u001b[38;5;241m.\u001b[39mImageFolder(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, x),\n\u001b[0;32m     29\u001b[0m                                           data_transforms[x])\n\u001b[0;32m     30\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m     31\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m {x: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(image_datasets[x], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     32\u001b[0m                                              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     33\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m data_transforms \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      3\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     ]),\n\u001b[0;32m     26\u001b[0m }\n\u001b[1;32m---> 28\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x: datasets\u001b[38;5;241m.\u001b[39mImageFolder(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mdata_dir\u001b[49m, x),\n\u001b[0;32m     29\u001b[0m                                           data_transforms[x])\n\u001b[0;32m     30\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m     31\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m {x: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(image_datasets[x], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     32\u001b[0m                                              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     33\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=(0.75,1.25), \n",
    "                               contrast=(0,2), \n",
    "                               saturation=(0,2), \n",
    "                               hue=(-0.5,0.5)),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), \n",
    "                                sigma=(0.1, 5)),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.RandomRotation(degrees=(0, 360)),\n",
    "        transforms.RandomAffine(degrees=(0, 360), \n",
    "                                translate=(0.1, 0.3), \n",
    "                                scale=(0.5, 0.75), \n",
    "                                shear=(0, 0.2, 0, 0.2)),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.Normalize(means, stds)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43393675-cb1e-4586-aa48-5ca8d2dd64be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T18:01:02.922675Z",
     "iopub.status.busy": "2022-07-31T18:01:02.922675Z",
     "iopub.status.idle": "2022-07-31T18:01:02.952676Z",
     "shell.execute_reply": "2022-07-31T18:01:02.951675Z",
     "shell.execute_reply.started": "2022-07-31T18:01:02.922675Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_te' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: TensorDataset(\u001b[43mx_train_te\u001b[49m,t_train_te),\n\u001b[0;32m      2\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: TensorDataset(x_test_te,t_test_te)}\n\u001b[0;32m      4\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m {x: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(image_datasets[x], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mcore_count)\n\u001b[0;32m      6\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_te' is not defined"
     ]
    }
   ],
   "source": [
    "image_datasets = {'train': TensorDataset(x_train_te,t_train_te),\n",
    "                 'val': TensorDataset(x_test_te,t_test_te)}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,\n",
    "                                             shuffle=True, num_workers=core_count)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f71425-b403-47e5-a0b7-bcd2a4a9c578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
