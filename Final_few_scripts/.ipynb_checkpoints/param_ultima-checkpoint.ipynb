{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeaf7e05-ae68-4000-935e-c765b5e930a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T00:01:19.714157Z",
     "iopub.status.busy": "2022-08-01T00:01:19.714157Z",
     "iopub.status.idle": "2022-08-01T00:01:23.319033Z",
     "shell.execute_reply": "2022-08-01T00:01:23.318529Z",
     "shell.execute_reply.started": "2022-08-01T00:01:19.714157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x17bf53bbee0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, accuracy_score, f1_score\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7016007e-11ea-4845-be65-b22197695002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T00:01:23.322528Z",
     "iopub.status.busy": "2022-08-01T00:01:23.322028Z",
     "iopub.status.idle": "2022-08-01T00:01:23.335030Z",
     "shell.execute_reply": "2022-08-01T00:01:23.334028Z",
     "shell.execute_reply.started": "2022-08-01T00:01:23.322528Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:  NVIDIA GeForce RTX 3060\n",
      "CPU cores:  0\n",
      "Working directory:  C:\\Users\\GCM\\Desktop\\GIT_REPOS\\FML_playground\\Final_few_scripts\n",
      "20:01:23\n"
     ]
    }
   ],
   "source": [
    "# use GPU when available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# Print GPU name\n",
    "print('GPU: ', torch.cuda.get_device_name(device=device))\n",
    "#number of usable CPU cores\n",
    "core_count = 0#len(os.sched_getaffinity(0)) #os.cpu_count() for local windows machine\n",
    "print('CPU cores: ', core_count)\n",
    "# current working directory\n",
    "wd = os.getcwd()\n",
    "print('Working directory: ', wd)\n",
    "\n",
    "# start time\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36b7b33-5cff-40e4-8901-d71b8de09849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T00:01:23.338532Z",
     "iopub.status.busy": "2022-08-01T00:01:23.337531Z",
     "iopub.status.idle": "2022-08-01T00:01:23.505254Z",
     "shell.execute_reply": "2022-08-01T00:01:23.504257Z",
     "shell.execute_reply.started": "2022-08-01T00:01:23.338034Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_dict = {'train':[[],[]], 'val':[[],[]]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.type(torch.LongTensor) \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            train_dict[phase][0].append(epoch_loss)\n",
    "            train_dict[phase][1].append(epoch_acc.cpu().item())\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89cc8cd8-769d-4d79-a204-78bdf59c49cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T00:01:23.507256Z",
     "iopub.status.busy": "2022-08-01T00:01:23.506754Z",
     "iopub.status.idle": "2022-08-01T00:01:23.659750Z",
     "shell.execute_reply": "2022-08-01T00:01:23.658749Z",
     "shell.execute_reply.started": "2022-08-01T00:01:23.507256Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloaders, epochs, gamma, step_size, learning_rate, class_num=10):\n",
    "    # load model\n",
    "    model_conv = torchvision.models.efficientnet_v2_l(weights='EfficientNet_V2_L_Weights.IMAGENET1K_V1')\n",
    "    for param in model_conv.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "    num_ftrs = model_conv.classifier[1].in_features\n",
    "    model_conv.classifier = nn.Linear(num_ftrs, class_num)\n",
    "    model_conv = model_conv.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Observe that only parameters of final layer are being optimized\n",
    "    optimizer_conv = optim.Adam(model_conv.classifier.parameters(), lr=learning_rate)\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=step_size, gamma=gamma)\n",
    "    # train model\n",
    "    best_model, train_dict_fixed = train_model(model_conv, \n",
    "                                               criterion, \n",
    "                                               optimizer_conv, \n",
    "                                               exp_lr_scheduler, \n",
    "                                               num_epochs=epochs,\n",
    "                                               dataloaders=dataloaders)\n",
    "    return best_model, train_dict_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d5e1df-25d8-40a9-b156-509c6b5a0f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T00:01:23.661250Z",
     "iopub.status.busy": "2022-08-01T00:01:23.660750Z",
     "iopub.status.idle": "2022-08-01T00:01:23.814194Z",
     "shell.execute_reply": "2022-08-01T00:01:23.813692Z",
     "shell.execute_reply.started": "2022-08-01T00:01:23.661250Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(best_model, dataloader, class_num=10):\n",
    "    model = torchvision.models.efficientnet_v2_l(weights='EfficientNet_V2_L_Weights.IMAGENET1K_V1')\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier = torch.nn.Linear(num_ftrs, class_num)\n",
    "    model.load_state_dict(best_model.state_dict())\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model.train(mode=False)\n",
    "    \n",
    "    cm=0\n",
    "    cm_multi=0\n",
    "    all_labels_lst = []\n",
    "    all_preds_lst = []\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.to(int)\n",
    "            multi_labels_lst = torch.nn.functional.one_hot(labels, num_classes=class_num).cpu().tolist()\n",
    "            labels_lst = labels.cpu().tolist()\n",
    "            all_labels_lst.append(labels_lst)\n",
    "            \n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            multi_preds_lst = (probabilities >= 0.9).type(torch.uint8).cpu().tolist()\n",
    "            preds_lst = torch.argmax(probabilities, axis=1).cpu().tolist()\n",
    "            all_preds_lst.append(preds_lst)\n",
    "\n",
    "            cm += confusion_matrix(y_true=labels_lst, y_pred=preds_lst, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "            cm_multi += multilabel_confusion_matrix(y_true=multi_labels_lst, y_pred=multi_preds_lst)\n",
    "            \n",
    "    all_labels_lst = sum(all_labels_lst, [])\n",
    "    all_preds_lst = sum(all_preds_lst, [])\n",
    "    print('Acc: ', accuracy_score(all_labels_lst, all_preds_lst))\n",
    "    print('Micro F1: ', f1_score(all_labels_lst, all_preds_lst, average='micro'))\n",
    "    \n",
    "    return cm, cm_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6891e0a2-f5e9-43e5-baa4-e15d9791db22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T00:01:23.815693Z",
     "iopub.status.busy": "2022-08-01T00:01:23.815693Z",
     "iopub.status.idle": "2022-08-01T00:01:23.983799Z",
     "shell.execute_reply": "2022-08-01T00:01:23.983296Z",
     "shell.execute_reply.started": "2022-08-01T00:01:23.815693Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, dataset, transform_list=None):\n",
    "        [data_X, data_y] = dataset\n",
    "        X_tensor, y_tensor = torch.Tensor(data_X), torch.Tensor(data_y)\n",
    "        tensors = (X_tensor, y_tensor)\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transforms = transform_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transforms:\n",
    "          #for transform in self.transforms: \n",
    "          #  x = transform(x)\n",
    "            x = self.transforms(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32476555-79a3-4c3e-b34f-87053e517fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T00:01:23.986799Z",
     "iopub.status.busy": "2022-08-01T00:01:23.986298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "data = np.load(wd+'/nodup_data.npy')\n",
    "labels = np.load(wd+'/nodup_labels.npy')\n",
    "\n",
    "# reshape data\n",
    "reshaped_data = data.reshape((300,300,3,data.shape[1]))\n",
    "# normalize parameters\n",
    "stds = reshaped_data.std(axis=(0,1,3))\n",
    "means = reshaped_data.mean(axis=(0,1,3))\n",
    "# move axis on data\n",
    "reshaped_data = np.moveaxis(reshaped_data, source=[0, 1, 2, 3], destination=[2, 3, 1, 0])\n",
    "labels = np.array(labels,dtype=int)\n",
    "\n",
    "# label names\n",
    "class_names = ['Stop','Yield','Red Light','Green Light','Roundabout','Right Turn Only',\n",
    "                'Do Not Enter','Crosswalk','Handicap Parking','No Parking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5305a9-ac1f-4c73-86bc-38ae07a10921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainset = [moveaxis_data,labels]\n",
    "\n",
    "# transform_comp = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.ColorJitter(brightness=(0.75,1.25), \n",
    "#                            contrast=(0,2), \n",
    "#                            saturation=(0,2), \n",
    "#                            hue=(-0.5,0.5)),\n",
    "#     transforms.GaussianBlur(kernel_size=(5, 9), \n",
    "#                             sigma=(0.1, 5)),\n",
    "#     transforms.RandomPerspective(),\n",
    "#     transforms.RandomRotation(degrees=(0, 360)),\n",
    "#     transforms.RandomAffine(degrees=(0, 360), \n",
    "#                             translate=(0.1, 0.3), \n",
    "#                             scale=(0.5, 0.75), \n",
    "#                             shear=(0, 0.2, 0, 0.2)),\n",
    "#     transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "#     transforms.Normalize(means, stds)\n",
    "#     ])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=(0.75,1.25), \n",
    "                               contrast=(0,2), \n",
    "                               saturation=(0,2), \n",
    "                               hue=None),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), \n",
    "                                sigma=(0.1, 5)),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.RandomRotation(degrees=(0, 360)),\n",
    "        transforms.RandomAffine(degrees=(0, 360), \n",
    "                                translate=(0.1, 0.3), \n",
    "                                scale=(0.5, 0.75), \n",
    "                                shear=(0, 0.2, 0, 0.2)),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "        transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "}\n",
    "# dataset_train = CustomTensorDataset(dataset=trainset, transform_list=transform_comp)\n",
    "\n",
    "# dataset_dataloader = torch.utils.data.DataLoader(dataset_train, \n",
    "#                                                  batch_size=4,\n",
    "#                                                  shuffle=True, \n",
    "#                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460630b-f2e2-42fc-995c-6bf7be670722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# # parameter ranges\n",
    "# kfolds = 5\n",
    "# epoch_count = 15\n",
    "# batch_size_lst = [1, 32, 64]\n",
    "# gamma_lst = [0.1, 0.2, 0.3]\n",
    "# step_size_lst = [1, 9, 15]\n",
    "# lr_lst = [0.001,0.01, 0.1]\n",
    "\n",
    "# # parameter ranges\n",
    "# kfolds = 5\n",
    "# epoch_count = 15\n",
    "# batch_size_lst = [64, 128, 256, 512]\n",
    "# gamma_lst = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "# step_size_lst = [1, 3, 5, 7]\n",
    "# lr_lst = [0.001, 0.005,0.01, 0.1]\n",
    "\n",
    "\n",
    "## Cross-Validated Parameters\n",
    "kfolds = 5\n",
    "epoch_count = 150\n",
    "batch_size_lst = [8]\n",
    "gamma_lst = [0.1]\n",
    "step_size_lst = [3]\n",
    "lr_lst = [0.1]\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "# split data into folds\n",
    "kf = KFold(n_splits=kfolds, random_state=42, shuffle=True)\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(reshaped_data):\n",
    "    x_train, x_test = reshaped_data[train_index], reshaped_data[test_index]\n",
    "    t_train, t_test = labels[train_index], labels[test_index]\n",
    "#     x_train_te = torch.Tensor(x_train)\n",
    "#     x_val_te = torch.Tensor(x_test)\n",
    "#     t_train_te = torch.Tensor(t_train)\n",
    "#     t_val_te = torch.Tensor(t_test)\n",
    "    trainset = [x_train,t_train]\n",
    "    testset = [x_test,t_test]\n",
    "    fold += 1\n",
    "    \n",
    "    for batch_size in batch_size_lst:\n",
    "        # turn tensors into data loaders\n",
    "        image_datasets = {'train': CustomTensorDataset(dataset=trainset, transform_list=data_transforms['train']), 'val': CustomTensorDataset(dataset=testset, transform_list=data_transforms['train'])}\n",
    "        dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                      batch_size=batch_size, \n",
    "                                                      shuffle=True, \n",
    "                                                      num_workers=core_count) for x in ['train', 'val']}\n",
    "        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "        # print('Data shapes',x_train_te.shape, x_val_te.shape, t_train_te.shape, t_val_te.shape)\n",
    "        \n",
    "        for gamma in gamma_lst:\n",
    "            for step_size in step_size_lst:\n",
    "                for learning_rate in lr_lst:\n",
    "                    file_name = 'multi_'+str(fold)+'_'+str(batch_size)+'_'+str(gamma)+'_'+str(step_size)+'_'+str(learning_rate)+'_cm_train.npy'\n",
    "                    if file_name in os.listdir():\n",
    "                        print('Already Exists')\n",
    "                    else:\n",
    "                        print('fold-batch_size-gamma-step_size-learning_rate', fold, batch_size, gamma, step_size, learning_rate)\n",
    "                        best_model, train_dict_fixed = train(dataloaders=dataloaders, \n",
    "                                                             epochs=epoch_count, \n",
    "                                                             gamma=gamma, \n",
    "                                                             step_size=step_size, \n",
    "                                                             learning_rate=learning_rate, \n",
    "                                                             class_num=10)\n",
    "\n",
    "                        # save training epoch data to disk\n",
    "                        df = pd.DataFrame()\n",
    "                        df['train_loss'] = train_dict_fixed['train'][0]\n",
    "                        df['val_loss'] = train_dict_fixed['val'][0]\n",
    "                        df['train_acc'] = train_dict_fixed['train'][1]\n",
    "                        df['val_acc'] = train_dict_fixed['val'][1]\n",
    "                        df.to_csv(wd+'/train_'+str(fold)+'_'+str(batch_size)+'_'+str(gamma)+'_'+str(step_size)+'_'+str(learning_rate)+'.csv')\n",
    "\n",
    "                        print('Val')\n",
    "                        cm, cm_multi = test(best_model=best_model, dataloader=dataloaders['val'])\n",
    "                        cm_df = pd.DataFrame(cm)\n",
    "                        cm_df.to_csv(wd+'/'+str(fold)+'_'+str(batch_size)+'_'+str(gamma)+'_'+str(step_size)+'_'+str(learning_rate)+'_cm_val.csv')\n",
    "                        np.save(wd+'/multi_'+str(fold)+'_'+str(batch_size)+'_'+str(gamma)+'_'+str(step_size)+'_'+str(learning_rate)+'_cm_val', cm_multi)\n",
    "\n",
    "                        print('Train')\n",
    "                        cm, cm_multi = test(best_model=best_model, dataloader=dataloaders['train'])\n",
    "                        cm_df = pd.DataFrame(cm)\n",
    "                        cm_df.to_csv(wd+'/'+str(fold)+'_'+str(batch_size)+'_'+str(gamma)+'_'+str(step_size)+'_'+str(learning_rate)+'_cm_train.csv')\n",
    "                        np.save(wd+'/multi_'+str(fold)+'_'+str(batch_size)+'_'+str(gamma)+'_'+str(step_size)+'_'+str(learning_rate)+'_cm_train', cm_multi)\n",
    "\n",
    "                        # end time \n",
    "                        t = time.localtime()\n",
    "                        current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "                        print('fold-batch_size-gamma-step_size-learning_rate', fold, batch_size, gamma, step_size, learning_rate)\n",
    "                        print('Done at: ', current_time)\n",
    "                        print('_____________________________________________\\n\\n')\n",
    "print('FINAL FINISHED')\n",
    "print('_____________________________________________\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5ad01-e422-4f35-ae93-af3f2e10497d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
